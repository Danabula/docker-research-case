---
title: Praktisch docker
order: 1
active: 1
goto:
 type: subject
 index: 4
---

# Praktisch docker

Docker is een collectie van software voor het draaien en managen van containers.  
Containers zijn een mannier van virtualizatie op het operating systeem level.  
Deze virtualizatie technologieen worden ookwel containerizatie genoemd.

Voordelen van docker zijn:
- Je hoeft het 1 keer in te pakken met docker en dan heb je alle voordelen van docker.
- Als het eenmaal opgezet is werkt het erg goed.
- Makkelijk omgeving updaten, bijvoorbeeld voor updaten van nodejs hoef je alleen de image tag te veranderen.
- Deployments zijn makkelijk.
- Meerdere versies met configuraties van software draaien zonder conflicten.
- Containers maken efficienter gebruikt van de host os resources dan virtuele machines, omdat containers dezelfde kernel als het host operating systeem gebruiken.

Een aantal nadelen zijn:
- Het cost veel tijd om op te zetten.
- Heeft best wel een learning curve, er is bijvoorbeeld veel context voor linux commandline nodig.

Docker wordt gebruikt:
- Voor (cloud) deployments, omdat je kan alleen docker op hoeft te zetten op de server, dat regelt de rest.  
- Ook wordt het gebruikt voor het development process omdat de computers vaak verschillende software en configuraties hebben.  
    Maar met containers kan je de software draaien zonder conflicten, bijvoorbeeld:  
    een developer heeft een project A met een mysql database op poort 3306, als project B met docker  
    dezelfde port gebruikt, is het makkelijk om de port te veranderen en beide applicaties te draaien zonder conflicten.
- Om programmas onafhankelijk van operating systeem en systeem configuratie op te zetten.  
    Dit betekend bijvoorbeeld dat je programmas die verschillende versies hebben op dezelfde computer kan draaien
- Voor service orchistratie.  
	Orchistratie is het dynamisch opzetten van meerdere computers en programmas (instanties & resources),  
    en docker biedt een abstractie over operating systemen, dus docker is handig voor orchistratie tools zoals kubernetes.
	- Redundancy, met container orchistratie is het mogelijk meerdere instanties van een programma te draaien.  
		Dat betekend dat als er iets verkeerd zoals een container crashed of er gaat bij een data center iets fout,  
        of er is server onderhoud nodig etc. dan is je website/service niet uit de lucht.
	- Ook is orchistratie heel handig voor als je website/service variable hoeveelheden van traffic heeft.  
		Bijvoorbeeld als jij een weervoorspelling site hebt, kan je elke ochtend een traffic spike krijgen.  
		Met orchistratie tools kan je dan automatisch containers erbij creeeren om overeind te blijven.
- Om te prototypen en experiementeren.  
    Als je met een container werkt is dat onafhankelijk van het operating systeem, dus je host os niet verknallen!  
    Als er iets verkeerd gaat met het opzetten van software, bijvoorbeeld een database, dan is dat heel gemakkelijk terug te zetten.
- Voor security.  
    Security werkt met lagen en de docker runtime isoleert het van het host systeem met de juiste configuraties,  
    zoals read only filesysteem mounts.

De workflow van docker is als volgt:
- Iemand verpakt een project/applicatie met docker tot een docker image.  
    Zo'n image kan je zien als een class of een blauwdruk.
- Je wilt gebruik maken van een docker image.  
    Dan kan jij docker vertellen om zo'n image te draaien.
- Om die docker applicatie te draaien moet je eerst een instantie van die image creeen, een container.  
    Zo'n container kan je zien als een een object of een instantie van een class.
- Dan draait docker de container (de applicatie zit erin).

Dit is handige structuur want dan kan je meerdere instanties van containers tegelijk draaien.
Nu gaan we verder duiken in het gebruik van docker.


---

## Containers gebruiken

Laten we beginnen met het hello world programma!
```shell
docker run hello-world
```
Nu zie je docker een image downloaden van de standard image repository: dockerhub.  
Een image is een door docker ingepakt programma en dockerhub heeft images voor veel programmas,  
zoals de mysql en mariadb databases, nodejs, php, basis operating systeem images, apache httpd, nginx etc.  
Zo'n image (vergelijkbaar met een class) kan je niet direct draaien, docker maakt een container (vergelijkbaar met een instantie) aan om te draaien.  
Na het downloading draait docker de container.  
Je kan ook argumenten doorgeven naar het programma dat de entrypoint draait, Bijvoorbeeld.
```shell
# de node -e of --eval optie staat voor evalueren, oftewel: javascript draaien
docker run node -e 'console.log("Hello nodejs runtime!")'
```
Zo kan je bijvoorbeeld een logging level argument geven aan het programma.

Nu heeft docker nog wel de images.  
Gebruik docker image ls om de gedownloade images weer te geven.
```shell
docker image ls
```
Met docker kan je draaiende containers weergeven met
```shell
docker ps
```
Er is nu geen actieve container, het hello world programma is al klaar met draaien.  
Er zijn ook programmas die blijven draaien totdat de gebruiker het programma stopt (een daemon).

Bijvoorbeeld een simpel python programma dat een infinite loop heeft.
```shell
# zet de locatie waar je python-entrypoint.sh kan vinden relatief met de working directory
script="src/sources/loop.py"
docker run -d --rm -e "MESSAGE=Hello python!" -v "$script:/script.py:ro" python:3-alpine python -u /script.py
```
Okay, hier gebeurt heel wat, laten we het stap voor stap dismantelen.  
Als eerste de -d optie geeft aan dat docker de container in de achtergrond moet draaien, dus dat docker niet je terminal blokkeerd.  
De --rm optie geeft aan dat de container verwijderd moet worden als het stopt.
De -e of --env optie is om een omgevings variable te zetten voor de container, programmas kunnen dit lezen en het is dus handig om de mode van je applicatie te zetten voor productie.
De -v optie is om een file of directory in de container te mounten, oftewel de script.py file in de container verwijst
naar de loop.py file.
Dan komt de naam van de image, waarvan we een container willen draaien: python:3-alpine.
Dit is een image met een python interpreter (kan python files draaien net zoals nodejs voor javascript).  
En als laatst het commando dat we willen draaien "python -i /script.py": de python interpreter om het script te draaien

Als je nu docker ps invoert, zie je 1 lijn met de python container (te zien aan de image naam).
```shell
docker ps
```
De containers krijgen een random container id en naam bij creatie, zodat we containers kunnen onderscheiden.  
Die kunnen we gebruiken om een commando voor een specifieke container uit te voeren, zoals docker logs om container logs te bekijken.  
Je hoeft voor de container id alleen maar de eerste karakters in te voeren, om het te onderscheiden van andere containers.
```shell
docker logs container-id
# of
docker logs container-naam
```
Nu zie je dat het python programma elke seconde Hello python! heeft geprint.
Om een contain te stoppen gebruik je docker stop
```shell
docker stop container-id
```
Maar de container is dan niet verwijderd. Dit is nodig om bijvoorbeeld de logs te kunnen bekijken als een container crashed.  
Gebruik docker ps met de -a vlag om ook inactive/gestopte containers te bekijken.
```shell
docker ps -a
```
Om een gestopte container te verwijderen gebruik je docker rm
```shell
docker rm container-id
```

Dus om docker images te gebruiken en beheren gebruik je
```shell
# voor een container draaien
docker run image-id (cmd)
# met -d voor in de achtergrond en --rm om de container te verwijderen wanneer het gestopt is
# voor een lijst van draaiende containers weer te geven
docker ps
# voor een lijst van active en inactive containers
docker ps -a
# om de logs van een container te bekijken
docker logs container-id
# om een container verwijderen
docker rm container-id
```
Bekijk vooral nog andere docker run opties zoals -p voor port forwarden en -v voor filesysteem passtrough.
```shell
docker --help
```


---

## Container images

Een docker image werkt door lagen van applicaties te installeren & commandos te draaien op een andere image.  
Onder al die lagen zit een basis image, die wel speciale preperatie nodig heeft [base images](https://docs.docker.com/build/building/base-images/)  
Maar je werkt in de praktijk vrijwel altijd al met een base image, zoals debian of alpine linux.  
Net zoals je in windows en linux na een installatie allemaal programmas installeerd, doen we dat ook met docker images.  
Linux distributies gebruiken een package manager net zoals npm, composer etc. voor gewone programmas installeren.  
Om bijvoorbeeld videolan player te installeren op archlinux gebruik je de pacman package manager.
```shell
pacman -S vlc
```
Een package manager verifieerd package integeriteit en maakt het makkelijk om programmas te installeren en updaten.  
Nou zo'n docker image bouwen doe je met een **Dockerfile**.  
Een dockerfile is een text file met de volgende structuur:
```dockerfile
FROM debian:latest
# dit is waar je de base image kiest, hierzo debian van de standard repository (dockerhub) met de latest tag (de laatste versie).

RUN apt update && apt install neofetch
# de RUN instructie wordt gebruikt een commandos uit te voeren.
# hier updaten we eerst de package database, oftewel welke programmas de package manager het bestaan van weet.
# apt is het commando van de debian package manager aptitude.
# en (&&) hier installeren we het programma neofetch, dat wordt gebruikt om informatie over een operating systeem laat zien.

RUN echo hallo we zijn een image aan het bouwen!
# als we deze Dockerfile gebruiken om een image te bouwen, zullen we "hallo we zijn een image aan het bouwen!" te zien krijgen.
# het sh echo commando print naar stdout, oftewel het doet hetzelfde als echo en print in programmeer talen>

ENTRYPOINT [ "neofetch" ]
# entrypoint is het commando dat wordt gedraaid, als je een container van deze image gebruikt.
```
Elk commando creeert een laag die gehashd wordt met de inhoud en de hash van de vorige laag,  
deze hash kan docker gebruiken om lagen te dedupliceren,  
het zou namelijk onhandig zijn als elke image die je maakt een heel kopie maakt van de base image, dat zou veel opslag kosten.  
Dit is waarom je vaak alleen een deel van een image moet herbouwen bij een verandering in je dockerfile, omdat vorige lagen al gecached zijn.  
Je kan docker history gebruiken om de verschillende lagen van een image te weergeven.
```shell
docker history id
```
Andere dockerfile commands zijn COPY, CMD. Zie de [referentie](https://docs.docker.com/engine/reference/builder/).  
Om je docker image daadwerkelijk te bouwen gebruik je docker build.  
Open een shell in de Dockerfile folder.
```shell
# build een image van context folder (zoekt een Dockerfile in dezelfde folder)
docker build -t mijn-neofetch .
# of een specifieke Dockerfile
docker build -t mijn-neofetch -f Dockerfile
```
Nu download docker de debian image en gaat het laag voor laag bouwen.  
Je ziet als docker klaar is met bouwen na STEP 3/4 de lijn: 'hallo we zijn een image aan het bouwen!'  
Nu kunnen we neofetch in een container draaien met docker run.
```shell
docker run --rm mijn-neofetch
```
Zoals je kunt zien met docker image ls en het downloaden & builden van de image,  
gebruikt het gigantisch veel disk ruimte voor alleen maar een mooi print programma.  
Een veelgebruikte operating systeem en docker base image is alpine linux, omdat het heel klein is.  
De alpine docker image is 8MB want het gebruikt de host kernel  
en is geoptimaliseerd voor virtualizatie, dus heeft alleen virtualizatie drivers.  
Nu kan je docker image verwijderen met docker image rm en docker containers met docker rm.
```shell
docker image rm id
# of de alias
docker rmi id
```
Dus om docker images te gebruiken en beheren gebruik je
```shell
# voor bouwen
docker build -t tag -f dockerfile
# voor een lijst van images
docker image ls
# voor verwijderen
docker image rm id
```
Om meer te leren over de docker cli kan je docker --help doen.
```shell
docker --help
```
en door de documentatie te lezen [Docker docs](https://docs.docker.com/).

**TODO Opdracht: refactor de neofetch dockerfile om alpine linux te gebruiken in plaats van debian**
**TODO Opdracht: refactor applicatie om containers te gebruiken (bash script) (requires installation of een package)**
**TODO** voor productie is het nodig om alle binaries en source files in de image zelf te hebben, zodat je niet zelf de html, php, js etc.
files hoeft te mounten.


---

## Docker compose

Docker compose is nodig als je met meerdere containers begint te werken.  
Het handmatig opstarting en stoppen en verwijderen van containers is natuurlijk niet handig als je het hebt over grootte  
aantallen containers die samenwerken om je applicatie te draaien.  
Dit kan je automatiseren met shell scripten, maar dan moet je ook zelf container netwerken en filesystemen regelen en er komen heel wat andere dingen bij kijken die je zou moeten automatiseren.  
Vooral wanneer er extra complexiteit bij komt met bijvoorbeeld een dependency van een container op een andere container,
zoals een webapp die een database nodig heeft, dan moet de database eerst in de lucht moet zijn voordat je de webapp start.
Het is niet er praktisch om zo'n complex script te onderhouden,
dus het zou handing zijn om het declaritief op te the kunnen schrijven.  
Docker compose is de tool die gemaakt is om zo containers te beheren.  
Je kan een docker-compose.yml [yaml](https://wikiless.tiekoetter.com/wiki/YAML?lang=en) text file schrijven.  

Een voorbeeld is een webapp met en een database, met een aantal verschillende configuraties.
De docker cli workflow zou er zo uitzien.
```shell
# creeer het netwerk voor het communiceren van de database en app
docker network create internal

# start de database in de achtergrond
docker run --rm --detach --network internal --name webapp-db -e "MARIADB_ROOT_PASSWORD=please-secure-for-prod" mariadb:latest

# wacht tot de database container gestart is; dat betekent dat het mariadb programma gestart is, niet dat de database all beschikbaar is!
until [ "$(docker inspect -f {{.State.Healthy}} webapp-db)"=="true" ]; do
    sleep 0.1;
done;

# start de webapp
docker run --rm --detach \
    --network internal \
    --name webapp-app \
    -e "DB_HOST=webapp-db" \
    -e "NODE_ENV=development" \
    -v "app.js:/app.js:ro" \
    -p "80:8000" \
    node /app.js

# stop & verwijder de webapp containers
docker stop webapp-db
docker stop webapp-app
docker network rm internal
```
Dat is wel onhandig om strict uit te typen.  
Voor de bovenstaande configuratie kan je een docker-compose bestand schrijven.
```yaml
# welke versie van de compose spec je gebruikt.
version: "3"

# mapping van container naam naar specificatie
services:
    db:
        image: mariadb:latest
        environment: 
            - MARIADB_ROOT_PASSWORD="please-secure-for-prod"
        networks:
            - intern

    app:
        image: node
        command: node /app.js
        depends_on:
            # wacht tot de database container draait
            - db
        volumes:
            # mount app.js in de container, anders kan node er niet bij
            - "app.js:/app.js:ro"
        environment:
            - DEPLOY="dev"
            - DB_HOST="db"
            - NODE_ENV="development"
        ports:
            # hier zijn we aan het port forwarden, dat betekent dat port 8000 van het intern network berijkt kan worden
            # vanaf de host port 80
            - "80:8000"
        # gebruik een los netwerk, want we willen geen port conficten met andere applicaties.
        # alleen port 80 wordt gebruikt voor deze webapp software stack van het perspectief van de host
        networks:
            - intern

networks:
    intern:
        driver: bridge
```
Dan je de webapp daarna makkelijk starten en stoppen.
```shell
# start de webapp in de achtergrond
docker-compose up -d
# stop de webapp
docker-compose down
```
Voor de verschillende docker-compose opties zie [docker compose reference](https://docs.docker.com/compose/compose-file/).


---

## Wat heb ik eraan?

Alles wat docker doet is het abstracten van de onderliggende systemen.  
Dan kan je applicaties met configuraties draaien op alle doel systemen.  
Dit is erg handig wanneer er meerdere developers of computers nodig zijn voor een project.  

Bijvoorbeeld
- Developers hebben hetzelfde omgeving, hoeven niet alle software te configureren, dus er zijn minder dingen
    die verkeerd kunnen gaan.  
    Zoals het installeren, configureren, conflicten, verschillende versies etc.
- Als je jouw project op een vps wilt zetten, dan is het makkelijk om alleen docker (met compose) te installeren
    en docker-compose up -d te draaien.  
    Dat is een stuk makelijker dan zelf alle software voor het host os op te moeten zetten.
- Ook lijkt je locale development omgeving op een productie server omgeving als ze beide docker gebruiken.


**Dus als je alles met docker draait kan je ervan uitgaan dat je project op andere machines werkt (met goed ingepakte images)!**


Zoals je ziet komt er heel wat bij kijken om docker te leren en images te maken.
- Het is niet geschikt als je ...
    - een simpel en klein project hebt
    - een gui applicatie maakt
    - niet bekent bent met docker
- Het is wel geschikt als je ...
    - met een team werkt, dan zorgt docker ervoor dat de omgeving van het programma hetzelfde is
    - project veel configuratie heeft  
        veel onderdelen zoals een http server, een database, een in-memory cache leiden ook tot meer configuratie  
    - programma complex is, want dan wordt het ook moeilijker om een development omgeving op te zetten
    - makkelijk een officiele image kan gebruiken voor jouw project.
        Populaire software heeft vaak goed onderhouden officiele docker images,  
        voorbeelden zijn: nodejs, php, apache httpd, nginx, etc.  
        [officiele images](https://hub.docker.com/search?q=&type=image&image_filter=official)
    - het programma op verschillende computers gaat draaien  
    - software of een bepaalde programmeer taal wilt proberen, dan kan dat zonder installeren en configureren


---

## Container orchistratie (bonus)
- docker swarm
- kubernetes

